# Xinference Q&A Agent

An intelligent AI-powered assistant that helps users find answers to their questions about Xinference. The agent searches through official documentation, GitHub issues, and source code to provide comprehensive answers with proper source attribution.

## Features

- **🔍 Intelligent Search**: Semantic search across multiple data sources
- **📚 Documentation Integration**: Search through official Xinference documentation
- **🐛 GitHub Issues**: Access real solutions from community discussions
- **💻 Source Code Search**: Find implementation details in the codebase
- **🤖 AI-Powered Responses**: Get comprehensive answers generated by AI
- **📊 Confidence Scoring**: Each answer includes a confidence score
- **⭐ Favorites & History**: Save useful answers and track search history
- **📱 Responsive Design**: Works on desktop and mobile devices

## Architecture

### Backend (FastAPI)
- **FastAPI** server with async endpoints
- **Semantic search** using sentence transformers and FAISS
- **Documentation scraper** for Xinference docs
- **GitHub API integration** for issues and code search
- **AI response generation** using GLM-4.5 API
- **Caching system** for improved performance

### Frontend (React)
- **React 18** with modern hooks and context
- **Tailwind CSS** for styling
- **React Router** for navigation
- **Axios** for API communication
- **React Markdown** for content rendering
- **Syntax highlighting** for code blocks

## Quick Start

### Prerequisites

- Python 3.8+
- Node.js 16+
- npm or yarn

### Backend Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd ask4xinf
   ```

2. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

4. **Run the backend server**
   ```bash
   cd backend
   python run.py
   ```

   The backend will be available at `http://localhost:8000`

### Frontend Setup

1. **Install Node.js dependencies**
   ```bash
   cd frontend
   npm install
   ```

2. **Install Tailwind CSS dependencies**
   ```bash
   npm install -D @tailwindcss/forms @tailwindcss/typography
   ```

3. **Start the development server**
   ```bash
   npm start
   ```

   The frontend will be available at `http://localhost:3000`

## Configuration

### Environment Variables

Create a `.env` file in the root directory:

```env
# OpenAI API Configuration (optional - for AI-powered responses)
OPENAI_API_KEY=your_openai_api_key_here

# GitHub API Configuration (optional - for better rate limits)
GITHUB_TOKEN=your_github_token_here

# Application Configuration
DEBUG=true
LOG_LEVEL=INFO

# Cache Configuration
CACHE_DURATION_HOURS=1
MAX_SEARCH_RESULTS=50

# Server Configuration
HOST=0.0.0.0
PORT=8000
```

### Optional Configuration

- **OpenAI API Key**: Enables AI-powered response generation. Without this, the system will provide basic responses using search results.
- **GitHub Token**: Increases API rate limits for GitHub searches. The system works without it but may hit rate limits with heavy usage.

## Usage

### Basic Usage

1. **Ask a Question**: Type your question in the search box
2. **Get Answers**: Receive AI-generated answers with source attribution
3. **Explore Sources**: Click on source links to dive deeper
4. **Save Favorites**: Click the heart icon to save useful answers
5. **View History**: Access your previous searches in the Search page

### Example Questions

- "How to install Xinference?"
- "CUDA out of memory error"
- "How to deploy models with Docker?"
- "How to use vLLM backend?"
- "Model loading fails"
- "How to configure GPU settings?"

### Search Tips

- Use natural language questions
- Be specific about your use case
- Include error messages for troubleshooting
- Mention your environment (Docker, Kubernetes, etc.)

## API Endpoints

### Main Endpoints

- `POST /api/ask` - Ask a question and get an AI-generated answer
- `GET /api/search/documentation` - Search documentation only
- `GET /api/search/github` - Search GitHub issues only
- `GET /api/search/code` - Search source code only
- `GET /api/popular-questions` - Get frequently asked questions
- `POST /api/feedback` - Submit feedback on answers

### Health Check

- `GET /health` - Check if the backend is running

## Development

### Project Structure

```
ask4xinf/
├── backend/
│   ├── main.py              # FastAPI application
│   ├── models/
│   │   └── schemas.py       # Pydantic models
│   ├── services/
│   │   ├── search_service.py      # Main search orchestration
│   │   ├── documentation_service.py  # Documentation scraping
│   │   ├── github_service.py      # GitHub API integration
│   │   └── response_service.py    # AI response generation
│   └── run.py               # Server startup script
├── frontend/
│   ├── src/
│   │   ├── components/      # React components
│   │   ├── pages/          # Page components
│   │   ├── contexts/       # React contexts
│   │   ├── services/       # API services
│   │   └── App.js          # Main app component
│   ├── public/             # Static files
│   └── package.json        # Node.js dependencies
├── requirements.txt         # Python dependencies
├── .env.example            # Environment variables template
└── README.md               # This file
```

### Adding New Features

1. **Backend**: Add new endpoints in `main.py` and implement logic in services
2. **Frontend**: Create new components and integrate with the API
3. **Search Sources**: Extend search services to include new data sources
4. **UI Components**: Add new components in the `components/` directory

### Testing

```bash
# Backend tests
cd backend
python -m pytest

# Frontend tests
cd frontend
npm test
```

## Deployment

### Docker Deployment

1. **Build the backend image**
   ```bash
   docker build -t xinference-qa-backend ./backend
   ```

2. **Build the frontend image**
   ```bash
   docker build -t xinference-qa-frontend ./frontend
   ```

3. **Run with Docker Compose**
   ```bash
   docker-compose up -d
   ```

### Production Deployment

1. **Backend**: Deploy using gunicorn or uvicorn with multiple workers
2. **Frontend**: Build and serve static files with nginx
3. **Database**: Consider adding PostgreSQL for persistent storage
4. **Caching**: Add Redis for improved caching
5. **Monitoring**: Add logging and monitoring solutions

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- **Xinference Team** for creating an amazing AI inference platform
- **OpenAI** for providing the AI capabilities
- **React and FastAPI communities** for excellent frameworks
- **Tailwind CSS** for beautiful styling utilities

## Support

If you encounter any issues or have questions:

1. Check the [GitHub Issues](https://github.com/xorbitsai/inference/issues)
2. Join the [Discord Community](https://discord.gg/Xw9tszSkr5)
3. Read the [Official Documentation](https://inference.readthedocs.io/)

---

**Note**: This is an unofficial community project and is not officially affiliated with the Xinference team.
